👏 文献阅读|Transformer的注意力机制

---
[TOC]

---
## 文章
Title: Attention Is All You Need  
Cited: 35980

## 创新
(1) 注意力机制是21世纪以来新一代人工智能算法中唯一的新算法。（CNN、MLP和RNN在很早以前就已经提出来了）  
(2) 是继MLP、CNN和RNN之后的第四大类模型。  
(3) 是一种简单新颖的模型，模型中完全没有用到CNN和RNN，是开创性的工作。  
(4) 旨在解决循环神经网络的缺点。  

## 摘要
(1) 是序列转录领域的一种模型算法。  
(2) 新颖简单的模型架构，完全没有使用CNN和RNN，仅使用了注意力机制。  
(3) 将模型算法在机器翻译领域应用，并行度更高，训练花费的时间更少，准确度也更高。  

## 背景
(1) 为了解决循环神经网络缺陷，首先使用CNN去替代RNN。但是使用CNN获得全局序列的信息需要构建很多卷积层，Transformer仅需要一层就能获取整条序列的相对信息。（Transformer相对卷积改造RNN的优势）  
(2) CNN可以设置多个卷积核去识别不同的模式，Transformer也使用了多头注意力识别不同的模式。
(3) 自注意力机制。  


## 方法


## 结果
(1) 第一个完全使用注意力的序列转录深度学习模型。  
(2) 其他在其他领域得到应用。  
(3) 代码：https://github.com/tensorflow/tensor2tensor.  
